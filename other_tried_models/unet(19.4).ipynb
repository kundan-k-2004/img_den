{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5afd2f-a0bd-4bd6-94fb-bdd0c8ba1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in layers tensorlow req \n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Cropping2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_size=256\n",
    "# img_size=128\n",
    "# img_size=64\n",
    "def load_images(image_dir, image_size=(img_size, img_size)):\n",
    "    images = []\n",
    "    for img_name in sorted(os.listdir(image_dir)):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        img = img_to_array(img) /255\n",
    "        images.append(img)\n",
    "       \n",
    "    return np.array(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3d783a-630b-4f32-8409-22d04a782324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape=(img_size,img_size,3)):\n",
    "    inputs=Input(input_shape)\n",
    "    \n",
    "    #encode\n",
    "    conv1=Conv2D(32,3,activation='relu',padding='same')(inputs)\n",
    "    conv1=Conv2D(32,3,activation='relu',padding='same')(conv1)\n",
    "    pool1=MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "    conv2=Conv2D(64,3,activation='relu',padding='same')(pool1)\n",
    "    conv2=Conv2D(64,3,activation='relu',padding='same')(conv2)\n",
    "    pool2=MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "\n",
    "    conv3=Conv2D(128,3,activation='relu',padding='same')(pool2)\n",
    "    conv3=Conv2D(128,3,activation='relu',padding='same')(conv3)\n",
    "    pool3=MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "\n",
    "    # base part\n",
    "    conv4=Conv2D(256,3,activation='relu',padding='same')(pool3)\n",
    "    conv4=Conv2D(256,3,activation='relu',padding='same')(conv4)\n",
    "\n",
    "    # decoder\n",
    "    up5=Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(conv4)\n",
    "    up5=concatenate([up5,conv3],axis=-1)\n",
    "    conv5=Conv2D(128,3,activation='relu',padding='same')(up5)\n",
    "    conv5=Conv2D(128,3,activation='relu',padding='same')(conv5)\n",
    "\n",
    "    up6=Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(conv5)\n",
    "    up6=concatenate([up6,conv2],axis=-1)\n",
    "    conv6=Conv2D(64,3,activation='relu',padding='same')(up6)\n",
    "    conv6=Conv2D(64,3,activation='relu',padding='same')(conv6)\n",
    "\n",
    "    up7=Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(conv6)\n",
    "    up7=concatenate([up7,conv1],axis=-1)\n",
    "    conv7=Conv2D(32,3,activation='relu',padding='same')(up7)\n",
    "    conv7=Conv2D(32,3,activation='relu',padding='same')(conv7)\n",
    "\n",
    "    outputs=Conv2D(3,1,activation='sigmoid')(conv7)\n",
    "    # linear is somehow worse search why\n",
    "\n",
    "    model=Model(inputs=[inputs],outputs=[outputs])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06b367c-c5a5-4411-9799-31be47b2c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    clean_images=load_images('./Train/high')\n",
    "    noisy_images=load_images('./Train/low')\n",
    "    train_noisy,val_noisy,train_clean,val_clean=train_test_split(noisy_images,clean_images,test_size=0.1,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model=unet(input_shape=(img_size,img_size,3))\n",
    "\n",
    "    datagen=ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    train_generator=datagen.flow(train_noisy,train_clean,batch_size=32)\n",
    "    val_generator=datagen.flow(val_noisy,val_clean,batch_size=32)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),loss='mean_squared_error')\n",
    "    # used rmsprop  \n",
    "\n",
    "\n",
    "    early_stopping=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
    "    model.fit(train_generator,epochs=10,validation_data=val_generator,callbacks=[early_stopping])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6bae1b-2e7e-449b-bc73-9fb0d2e6a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mention source of this part code \n",
    "def evaluate_model(model, clean_images, noisy_images):\n",
    "    predictions = model.predict(noisy_images)\n",
    "    mse_scores = [mse(clean, pred) for clean, pred in zip(clean_images, predictions)]\n",
    "    psnr_scores = [psnr(clean, pred) for clean, pred in zip(clean_images, predictions)]\n",
    "    mae_scores = [mae(clean.flatten(), pred.flatten()) for clean, pred in zip(clean_images, predictions)]\n",
    "    \n",
    "    print(f\"Mean MSE: {np.mean(mse_scores)}\")\n",
    "    print(f\"Mean PSNR: {np.mean(psnr_scores)}\")\n",
    "    print(f\"Mean MAE: {np.mean(mae_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71565a39-2193-493c-9229-13a98cd2b5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunda\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 7s/step - loss: 0.0503 - val_loss: 0.0491\n",
      "Epoch 2/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - loss: 0.0490 - val_loss: 0.0483\n",
      "Epoch 3/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - loss: 0.0464 - val_loss: 0.0485\n",
      "Epoch 4/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - loss: 0.0480 - val_loss: 0.0489\n",
      "Epoch 5/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - loss: 0.0473 - val_loss: 0.0483\n",
      "Epoch 6/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 6s/step - loss: 0.0488 - val_loss: 0.0481\n",
      "Epoch 7/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 6s/step - loss: 0.0467 - val_loss: 0.0482\n",
      "Epoch 8/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - loss: 0.0480 - val_loss: 0.0475\n",
      "Epoch 9/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - loss: 0.0473 - val_loss: 0.0478\n",
      "Epoch 10/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - loss: 0.0467 - val_loss: 0.0475\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step\n",
      "Mean MSE: 0.04198443314171405\n",
      "Mean PSNR: 14.21472389408663\n",
      "Mean MAE: 0.16976924240589142\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 737ms/step\n"
     ]
    }
   ],
   "source": [
    "# sover guy this calles only if main \n",
    "if __name__ == '__main__':\n",
    "    model = train_model()\n",
    "    \n",
    "    clean_images =load_images('./Train/high')\n",
    "    noisy_images=load_images('./Train/low')\n",
    "\n",
    "    evaluate_model(model, clean_images, noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47484232-1108-4044-b3bb-0ecea92c8338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'denoising_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# saving model not doing again\n",
    "model.save('advdsv.h5')\n",
    "\n",
    "print(\"Model saved as 'advdsv.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75092185-08a2-4308-9eef-564bdb8b6b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
